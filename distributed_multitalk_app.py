#!/usr/bin/env python3
# Copyright 2024-2025 The Alibaba Wan Team Authors. All rights reserved.

"""
åˆ†å¸ƒå¼MultiTalkåŒäººå¯¹è¯è§†é¢‘ç”ŸæˆWebæœåŠ¡

åŠŸèƒ½ç‰¹æ€§:
- æ”¯æŒä¸¤ä¸ªäººç‰©å›¾ç‰‡ä¸Šä¼ 
- æ™ºèƒ½å¯¹è¯è„šæœ¬è§£æ 
- è‡ªåŠ¨TTSè¯­éŸ³ç”Ÿæˆ
- 720Pé«˜æ¸…è§†é¢‘è¾“å‡º
- 8å¼ RTX-4090åˆ†å¸ƒå¼æ¨ç†
- å‹å¥½çš„Webç•Œé¢

ä½¿ç”¨æ–¹æ³•:
# å•GPUæµ‹è¯•è¿è¡Œ
python distributed_multitalk_app.py

# 8GPUåˆ†å¸ƒå¼è¿è¡Œ  
torchrun --nproc_per_node=8 distributed_multitalk_app.py --ulysses_size=8 --dit_fsdp --t5_fsdp

ä½œè€…: MultiTalkå›¢é˜Ÿ
ç‰ˆæœ¬: 1.0.0
"""

import os
import sys
import logging
import argparse
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(str(Path(__file__).parent))

from distributed_multitalk_core import _parse_args
from distributed_generator import DistributedMultiTalkGenerator
from distributed_web_interface import create_gradio_interface


def main():
    """ä¸»å‡½æ•°"""
    
    # æ‰“å°å¯åŠ¨ä¿¡æ¯
    print("=" * 60)
    print("ğŸ¬ åˆ†å¸ƒå¼MultiTalkåŒäººå¯¹è¯è§†é¢‘ç”ŸæˆæœåŠ¡")
    print("=" * 60)
    print("åŠŸèƒ½ç‰¹æ€§:")
    print("- ğŸ‘¥ åŒäººå›¾ç‰‡åˆæˆ")
    print("- ğŸ’¬ æ™ºèƒ½å¯¹è¯è§£æ") 
    print("- ğŸ¤ è‡ªåŠ¨TTSç”Ÿæˆ")
    print("- ğŸ“º 720Pé«˜æ¸…è¾“å‡º")
    print("- ğŸš€ åˆ†å¸ƒå¼æ¨ç†")
    print("=" * 60)
    
    # è§£æå‚æ•°
    args = _parse_args()
    
    # æ˜¾ç¤ºé…ç½®ä¿¡æ¯
    print("é…ç½®ä¿¡æ¯:")
    print(f"- ä»»åŠ¡ç±»å‹: {args.task}")
    print(f"- è§†é¢‘åˆ†è¾¨ç‡: {args.size}")
    print(f"- å¸§æ•°: {args.frame_num}")
    print(f"- Ulysseså¹¶è¡Œåº¦: {args.ulysses_size}")
    print(f"- Ringå¹¶è¡Œåº¦: {args.ring_size}")
    print(f"- T5 FSDP: {args.t5_fsdp}")
    print(f"- DiT FSDP: {args.dit_fsdp}")
    print(f"- æœåŠ¡ç«¯å£: {args.server_port}")
    print("=" * 60)
    
    try:
        # åˆ›å»ºåˆ†å¸ƒå¼ç”Ÿæˆå™¨
        print("æ­£åœ¨åˆå§‹åŒ–åˆ†å¸ƒå¼ç”Ÿæˆå™¨...")
        generator = DistributedMultiTalkGenerator(args)
        print("âœ… åˆ†å¸ƒå¼ç”Ÿæˆå™¨åˆå§‹åŒ–å®Œæˆ")
        
        # åˆ›å»ºWebç•Œé¢
        print("æ­£åœ¨åˆ›å»ºWebç•Œé¢...")
        demo = create_gradio_interface(generator)
        print("âœ… Webç•Œé¢åˆ›å»ºå®Œæˆ")
        
        # å¯åŠ¨æœåŠ¡
        print(f"æ­£åœ¨å¯åŠ¨WebæœåŠ¡ (ç«¯å£: {args.server_port})...")
        print("=" * 60)
        print("ğŸŒ æœåŠ¡å¯åŠ¨æˆåŠŸï¼")
        print(f"ğŸ“± è®¿é—®åœ°å€: http://localhost:{args.server_port}")
        print(f"ğŸ”— å¤–ç½‘è®¿é—®: http://0.0.0.0:{args.server_port}")
        print("=" * 60)
        print("ğŸ¯ ä½¿ç”¨è¯´æ˜:")
        print("1. åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€ä¸Šè¿°åœ°å€")
        print("2. ä¸Šä¼ ä¸¤ä¸ªäººç‰©å›¾ç‰‡")
        print("3. è¾“å…¥å¯¹è¯å°è¯è„šæœ¬")
        print("4. æè¿°åœºæ™¯ç¯å¢ƒ")
        print("5. ç‚¹å‡»ç”ŸæˆæŒ‰é’®ç­‰å¾…720Pè§†é¢‘")
        print("=" * 60)
        
        # å¯åŠ¨GradioæœåŠ¡
        demo.launch(
            server_name="0.0.0.0",
            server_port=args.server_port,
            debug=True,
            share=False,  # åˆ†å¸ƒå¼ç¯å¢ƒä¸å»ºè®®å¼€å¯share
            show_api=False,
            quiet=False
        )
        
    except KeyboardInterrupt:
        print("\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­ï¼Œæ­£åœ¨å…³é—­æœåŠ¡...")
        
    except Exception as e:
        print(f"âŒ å¯åŠ¨æœåŠ¡æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        logging.error(f"Service startup error: {e}", exc_info=True)
        sys.exit(1)
        
    finally:
        print("ğŸ”š æœåŠ¡å·²å…³é—­")


def validate_environment():
    """éªŒè¯è¿è¡Œç¯å¢ƒ"""
    
    # æ£€æŸ¥å¿…è¦çš„ç›®å½•
    required_dirs = [
        "weights/Wan2.1-I2V-14B-720P",
        "weights/chinese-wav2vec2-base", 
        "weights/Kokoro-82M"
    ]
    
    missing_dirs = []
    for dir_path in required_dirs:
        if not Path(dir_path).exists():
            missing_dirs.append(dir_path)
    
    if missing_dirs:
        print("âŒ ç¼ºå°‘å¿…è¦çš„æ¨¡å‹æ–‡ä»¶ç›®å½•:")
        for dir_path in missing_dirs:
            print(f"   - {dir_path}")
        print("\nè¯·ç¡®ä¿å·²ä¸‹è½½æ‰€æœ‰å¿…è¦çš„æ¨¡å‹æ–‡ä»¶")
        return False
    
    # æ£€æŸ¥GPU
    try:
        import torch
        if not torch.cuda.is_available():
            print("âš ï¸  è­¦å‘Š: æœªæ£€æµ‹åˆ°CUDA GPUï¼Œå°†ä½¿ç”¨CPUè¿è¡Œï¼ˆé€Ÿåº¦è¾ƒæ…¢ï¼‰")
        else:
            gpu_count = torch.cuda.device_count()
            print(f"âœ… æ£€æµ‹åˆ° {gpu_count} å¼ GPU")
            
            if gpu_count >= 8:
                print("ğŸš€ æ¨èä½¿ç”¨8GPUåˆ†å¸ƒå¼æ¨¡å¼ä»¥è·å¾—æœ€ä½³æ€§èƒ½")
                print("   å¯åŠ¨å‘½ä»¤: torchrun --nproc_per_node=8 distributed_multitalk_app.py --ulysses_size=8 --dit_fsdp --t5_fsdp")
            
    except ImportError:
        print("âŒ æœªæ‰¾åˆ°PyTorchï¼Œè¯·å…ˆå®‰è£…PyTorch")
        return False
    
    return True


if __name__ == "__main__":
    
    # éªŒè¯ç¯å¢ƒ
    if not validate_environment():
        sys.exit(1)
    
    # å¯åŠ¨æœåŠ¡
    main()