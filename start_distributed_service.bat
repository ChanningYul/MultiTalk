@echo off
REM åˆ†å¸ƒå¼MultiTalkåŒäººå¯¹è¯è§†é¢‘ç”ŸæˆæœåŠ¡å¯åŠ¨è„šæœ¬ (Windowsç‰ˆæœ¬)
REM é€‚ç”¨äº8å¼ RTX-4090 GPUç¯å¢ƒ

echo ============================================================
echo ğŸ¬ åˆ†å¸ƒå¼MultiTalkåŒäººå¯¹è¯è§†é¢‘ç”ŸæˆæœåŠ¡å¯åŠ¨è„šæœ¬
echo ============================================================

REM æ£€æŸ¥å‚æ•°
if "%1"=="--help" goto :help
if "%1"=="-h" goto :help
if "%1"=="/?" goto :help

REM è®¾ç½®æ¨¡å¼
set MODE=%1
if "%MODE%"=="" set MODE=distributed

REM è®¾ç½®ç¯å¢ƒå˜é‡
set CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
set NCCL_IB_DISABLE=1
set NCCL_P2P_DISABLE=1

REM æ£€æŸ¥å¿…è¦æ–‡ä»¶
echo ğŸ” æ£€æŸ¥å¿…è¦æ–‡ä»¶...

if not exist "distributed_multitalk_app.py" (
    echo âŒ ç¼ºå°‘æ–‡ä»¶: distributed_multitalk_app.py
    exit /b 1
)
if not exist "distributed_generator.py" (
    echo âŒ ç¼ºå°‘æ–‡ä»¶: distributed_generator.py
    exit /b 1
)
if not exist "distributed_web_interface.py" (
    echo âŒ ç¼ºå°‘æ–‡ä»¶: distributed_web_interface.py
    exit /b 1
)
if not exist "distributed_multitalk_core.py" (
    echo âŒ ç¼ºå°‘æ–‡ä»¶: distributed_multitalk_core.py
    exit /b 1
)

echo âœ… æ–‡ä»¶æ£€æŸ¥å®Œæˆ

REM æ£€æŸ¥æ¨¡å‹ç›®å½•
echo ğŸ” æ£€æŸ¥æ¨¡å‹ç›®å½•...

if not exist "weights\Wan2.1-I2V-14B-480P" (
    echo âŒ ç¼ºå°‘ç›®å½•: weights\Wan2.1-I2V-14B-480P
    echo è¯·ç¡®ä¿å·²ä¸‹è½½æ‰€æœ‰å¿…è¦çš„æ¨¡å‹æ–‡ä»¶
    exit /b 1
)
if not exist "weights\chinese-wav2vec2-base" (
    echo âŒ ç¼ºå°‘ç›®å½•: weights\chinese-wav2vec2-base
    echo è¯·ç¡®ä¿å·²ä¸‹è½½æ‰€æœ‰å¿…è¦çš„æ¨¡å‹æ–‡ä»¶
    exit /b 1
)
if not exist "weights\Kokoro-82M" (
    echo âŒ ç¼ºå°‘ç›®å½•: weights\Kokoro-82M
    echo è¯·ç¡®ä¿å·²ä¸‹è½½æ‰€æœ‰å¿…è¦çš„æ¨¡å‹æ–‡ä»¶
    exit /b 1
)

echo âœ… æ¨¡å‹ç›®å½•æ£€æŸ¥å®Œæˆ

REM æ ¹æ®æ¨¡å¼å¯åŠ¨
if "%MODE%"=="single" goto :single
if "%MODE%"=="distributed" goto :distributed

echo âŒ æœªçŸ¥æ¨¡å¼: %MODE%
echo æ”¯æŒçš„æ¨¡å¼: single, distributed
exit /b 1

:single
echo ğŸ”§ å¯åŠ¨æ¨¡å¼: å•GPU (æµ‹è¯•)
echo âš ï¸  æ³¨æ„: å•GPUæ¨¡å¼ä»…ä¾›æµ‹è¯•ï¼Œç”Ÿæˆé€Ÿåº¦è¾ƒæ…¢
echo ============================================================

python distributed_multitalk_app.py ^
    --ulysses_size=1 ^
    --ring_size=1 ^
    --server_port=8419

goto :end

:distributed
echo ğŸš€ å¯åŠ¨æ¨¡å¼: 8GPUåˆ†å¸ƒå¼ (æ¨è)
echo ğŸ“Š GPUé…ç½®: 8å¼ RTX-4090
echo âš¡ å¹¶è¡Œé…ç½®: Ulysses=8, Ring=1, FSDP=True
echo ğŸ¯ åˆ†è¾¨ç‡: 720P (960x960)
echo ============================================================

torchrun --nproc_per_node=8 ^
    --master_port=29500 ^
    distributed_multitalk_app.py ^
    --ulysses_size=8 ^
    --ring_size=1 ^
    --t5_fsdp ^
    --dit_fsdp ^
    --server_port=8419 ^
    --num_persistent_param_in_dit=0

goto :end

:help
echo ä½¿ç”¨æ–¹æ³•:
echo   %0 [single^|distributed]
echo.
echo å‚æ•°è¯´æ˜:
echo   single       - å•GPUæ¨¡å¼ (æµ‹è¯•ç”¨)
echo   distributed  - 8GPUåˆ†å¸ƒå¼æ¨¡å¼ (æ¨è)
echo.
echo ç¤ºä¾‹:
echo   %0 single       # å•GPUæµ‹è¯•
echo   %0 distributed  # 8GPUåˆ†å¸ƒå¼
echo   %0              # é»˜è®¤8GPUåˆ†å¸ƒå¼
exit /b 0

:end
echo ============================================================
echo ğŸ”š æœåŠ¡å·²åœæ­¢
pause