#!/bin/bash

# åˆ†å¸ƒå¼MultiTalkåŒäººå¯¹è¯è§†é¢‘ç”ŸæˆæœåŠ¡å¯åŠ¨è„šæœ¬
# é€‚ç”¨äº8å¼ RTX-4090 GPUç¯å¢ƒ

echo "============================================================"
echo "ğŸ¬ åˆ†å¸ƒå¼MultiTalkåŒäººå¯¹è¯è§†é¢‘ç”ŸæˆæœåŠ¡å¯åŠ¨è„šæœ¬"
echo "============================================================"

# æ£€æŸ¥å‚æ•°
if [ "$1" = "--help" ] || [ "$1" = "-h" ]; then
    echo "ä½¿ç”¨æ–¹æ³•:"
    echo "  $0 [single|distributed]"
    echo ""
    echo "å‚æ•°è¯´æ˜:"
    echo "  single       - å•GPUæ¨¡å¼ (æµ‹è¯•ç”¨)"
    echo "  distributed  - 8GPUåˆ†å¸ƒå¼æ¨¡å¼ (æ¨è)"
    echo ""
    echo "ç¤ºä¾‹:"
    echo "  $0 single       # å•GPUæµ‹è¯•"
    echo "  $0 distributed  # 8GPUåˆ†å¸ƒå¼"
    echo "  $0              # é»˜è®¤8GPUåˆ†å¸ƒå¼"
    exit 0
fi

# è®¾ç½®æ¨¡å¼
MODE=${1:-distributed}

# è®¾ç½®ç¯å¢ƒå˜é‡
export CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
export NCCL_IB_DISABLE=1
export NCCL_P2P_DISABLE=1

# æ£€æŸ¥å¿…è¦æ–‡ä»¶
echo "ğŸ” æ£€æŸ¥å¿…è¦æ–‡ä»¶..."

required_files=(
    "distributed_multitalk_app.py"
    "distributed_generator.py" 
    "distributed_web_interface.py"
    "distributed_multitalk_core.py"
)

for file in "${required_files[@]}"; do
    if [ ! -f "$file" ]; then
        echo "âŒ ç¼ºå°‘æ–‡ä»¶: $file"
        exit 1
    fi
done

echo "âœ… æ–‡ä»¶æ£€æŸ¥å®Œæˆ"

# æ£€æŸ¥æ¨¡å‹ç›®å½•
echo "ğŸ” æ£€æŸ¥æ¨¡å‹ç›®å½•..."

required_dirs=(
    "weights/Wan2.1-I2V-14B-480P"
    "weights/chinese-wav2vec2-base"
    "weights/Kokoro-82M"
)

for dir in "${required_dirs[@]}"; do
    if [ ! -d "$dir" ]; then
        echo "âŒ ç¼ºå°‘ç›®å½•: $dir"
        echo "è¯·ç¡®ä¿å·²ä¸‹è½½æ‰€æœ‰å¿…è¦çš„æ¨¡å‹æ–‡ä»¶"
        exit 1
    fi
done

echo "âœ… æ¨¡å‹ç›®å½•æ£€æŸ¥å®Œæˆ"

# æ ¹æ®æ¨¡å¼å¯åŠ¨
if [ "$MODE" = "single" ]; then
    echo "ğŸ”§ å¯åŠ¨æ¨¡å¼: å•GPU (æµ‹è¯•)"
    echo "âš ï¸  æ³¨æ„: å•GPUæ¨¡å¼ä»…ä¾›æµ‹è¯•ï¼Œç”Ÿæˆé€Ÿåº¦è¾ƒæ…¢"
    echo "============================================================"
    
    python distributed_multitalk_app.py \
        --ulysses_size=1 \
        --ring_size=1 \
        --server_port=8419
        
elif [ "$MODE" = "distributed" ]; then
    echo "ğŸš€ å¯åŠ¨æ¨¡å¼: 8GPUåˆ†å¸ƒå¼ (æ¨è)"
    echo "ğŸ“Š GPUé…ç½®: 8å¼ RTX-4090"
    echo "âš¡ å¹¶è¡Œé…ç½®: Ulysses=8, Ring=1, FSDP=True"
    echo "ğŸ¯ åˆ†è¾¨ç‡: 720P (960x960)"
    echo "============================================================"
    
    torchrun --nproc_per_node=8 \
        --master_port=29500 \
        distributed_multitalk_app.py \
        --ulysses_size=8 \
        --ring_size=1 \
        --t5_fsdp \
        --dit_fsdp \
        --server_port=8419 \
        --num_persistent_param_in_dit=0
        
else
    echo "âŒ æœªçŸ¥æ¨¡å¼: $MODE"
    echo "æ”¯æŒçš„æ¨¡å¼: single, distributed"
    exit 1
fi

echo "============================================================"
echo "ğŸ”š æœåŠ¡å·²åœæ­¢"